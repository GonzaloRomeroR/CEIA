{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementación de PCA en NumPy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objetivos\n",
    "* Implementación de PCA en NumPy paso a paso\n",
    "* Comparación de resultados con Scikit-learn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementación"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Dado un dataset $X \\in \\mathbb{R}^{n, d}$, con $n$ muestras y $d$ features, queremos reducir sus dimensiones a $m$. Para ello, el primer paso es centrar el dataset (Hint: usen np.mean)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "X = np.array([[0.8, 0.7], [0.1, -0.1]])\r\n",
    "\r\n",
    "means = np.mean(X, axis=0)\r\n",
    "center_samples = X - means\r\n",
    "center_samples"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.35,  0.4 ],\n",
       "       [-0.35, -0.4 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Obtener la matriz de covarianza de $X^T$, revisar en la teoría por qué utilizamos la transpuesta. Buscar en la documentación de NumPy qué funciones se pueden utilizar."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "covariance = np.cov(center_samples.T)\r\n",
    "covariance"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.245, 0.28 ],\n",
       "       [0.28 , 0.32 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Calcular los autovalores y autovectores de la matriz de covarianza. Revisar la documentación de NumPy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "eig_val, eig_vect = np.linalg.eig(covariance)\r\n",
    "eig_val, eig_vect"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.   , 0.565]),\n",
       " array([[-0.75257669, -0.65850461],\n",
       "        [ 0.65850461, -0.75257669]]))"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Ordernar los autovectores en el sentido de los autovalores decrecientes, revisar la teoría de ser necesario."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "index_order = np.argsort(-eig_val)\r\n",
    "eig_vect_ord = eig_vect[:, index_order]\r\n",
    "eig_val_ord = eig_val[index_order]\r\n",
    "eig_vect_ord"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.65850461, -0.75257669],\n",
       "       [-0.75257669,  0.65850461]])"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Proyectar el dataset centrado sobre los $m$ autovectores más relevantes (Hint: usen np.dot)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "center_samples.dot(eig_vect_ord[:, :m])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.53150729],\n",
       "       [ 0.53150729]])"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Consolidar los pasos anteriores en una función o clase PCA."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "def pca(X, m):\r\n",
    "    center_samples = X - np.mean(X, axis=0)\r\n",
    "    covariance = np.cov(center_samples.T)\r\n",
    "    eig_val, eig_vect = np.linalg.eig(covariance)\r\n",
    "    index_order = np.argsort(-eig_val)\r\n",
    "    eig_vect_ord = eig_vect[:, index_order]\r\n",
    "    eig_val_ord = eig_val[index_order]\r\n",
    "    return eig_val_ord[:m], center_samples.dot(eig_vect_ord[:m, :].T)\r\n",
    "    \r\n",
    "X = np.array([[0.8, 0.7], [0.1, -0.1]])\r\n",
    "m = 1\r\n",
    "pca_np = pca(X, m)\r\n",
    "print(\"Los valores obtenidos utilizando numpy son {}\".format(pca_np))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Los valores obtenidos utilizando numpy son (array([0.565]), array([[-0.53150729],\n",
      "       [ 0.53150729]]))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Comparar los resultados obtenidos con el modelo de PCA implementado en Scikit-learn ([ver documentación](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)). Tomar como dataset:\n",
    "\n",
    "$X=\\begin{bmatrix}\n",
    "0.8 & 0.7\\\\\n",
    "0.1 & -0.1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Se debe reducir a un componente. Verificar los resultados con np.testing.assert_allclose"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "X = np.array([[0.8, 0.7], [0.1, -0.1]])\r\n",
    "pca = PCA(n_components=1)\r\n",
    "print(pca.fit_transform(X))\r\n",
    "print(pca.explained_variance_)\r\n",
    "\r\n",
    "np.testing.assert_allclose(pca.fit_transform(X), pca_np[1])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-0.53150729]\n",
      " [ 0.53150729]]\n",
      "[0.565]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "381eb007a34d8c1cdb905850c2f3106cb914c7dd3c02e711b593e7e3b228bf2b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}